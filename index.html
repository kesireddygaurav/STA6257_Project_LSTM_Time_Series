<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gaurav Kesireddy">

<title>STA6257_Project_LSTM_Time_Series</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">STA6257_Project_LSTM_Time_Series</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Gaurav Kesireddy </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">Invalid Date</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Recurrent networks can in principle use their feedback connections to store representations of recent input events in form of activation’s (“short-term memory”, as opposed to “long-term memory embodied by slowly changing weights). The most widely used algorithms for learning what to put in short-term memory, however, take too much time or do not work well at all, especially when minimal time lags between inputs and corresponding teacher signals are long. With conventional”Back-Propagation Through Time” or “Real-Time Recurrent Learning”, error signals “flowing backwards in time” tend to either (1) blow up or (2) vanish: the temporal evolution of the back-propagated error exponentially depends on the size of the weights. Case (1) may lead to oscillating weights, while in case (2) learning to bridge long time lags takes a prohibitive amount of time, or does not work at all. Long Short-Term Memory(LSTM), a novel recurrent network architecture in conjunction with an appropriate gradient based learning algorithm comes up as a remedy to solve this problem. It can learn to bridge time intervals in excess of 1000 steps even in case of noisy, in-compressible input sequences, without loss of short term time lag capabilities. This is achieved by an efficient, gradient-based algorithm for an architecture enforcing constant error flow through internal states of special units.<span class="citation" data-cites="hochreiter1997long">(<a href="#ref-hochreiter1997long" role="doc-biblioref">Hochreiter and Schmidhuber 1997</a>)</span> Recurrent neural networks with Long Short-term Memory have emerged as an effective and scalable model for several learning problems related to sequential data. The central idea behind the LSTM architecture is a memory cell which can maintain its state over time, and non-linear gating units which regulate the information flow into and out of the cell. Most modern studies incorporate many improvements that have been made to the LSTM architecture since its original formulation.However, LSTM’s are now applied to many learning problems which differ significantly in scale and nature from the problems that these improvements were initially tested on.<span class="citation" data-cites="greff2016lstm">(<a href="#ref-greff2016lstm" role="doc-biblioref">Greff et al. 2016</a>)</span></p>
<p>A vanilla LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. This forget gate was not initially a part of the LSTM network, but was proposed later by <span class="citation" data-cites="gers2001lstm">(<a href="#ref-gers2001lstm" role="doc-biblioref">Gers and Schmidhuber 2001</a>)</span> to allow the network to reset its state. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information associated with the cell.<span class="citation" data-cites="greff2016lstm">(<a href="#ref-greff2016lstm" role="doc-biblioref">Greff et al. 2016</a>)</span></p>
<p><img src="Vanilla_LSTM.png" class="img-fluid" width="1068"></p>
<p><strong>Figure 1</strong> Architecture of a typical vanilla LSTM block.</p>
<p>The LSTM architecture consists of a set of recurrently connected sub-networks, known as memory blocks. The idea behind the memory block is to maintain its state over time and regulate the information flow thought non-linear gating units. The Fig. 1 displays the architecture of a vanilla LSTM block, which involves the gates, the input signal <span class="math inline">\(x^{(t)}\)</span>, the output <span class="math inline">\(y^{(t)}\)</span>, the activation functions and the peephole connections. The output of the block is recurrently connected back to the block input and all of the gates.</p>
<p>We can describe how the LSTM model works in details by assuming a network comprising N processing blocks and M inputs. The forward pass is this recurrent neural system is described in 6 parts.</p>
<p><strong>Block input</strong>. This step involves updating the block input component which combines the current input <span class="math inline">\(x^{(t)}\)</span> and the output of that LSTM unit <span class="math inline">\(y^{(t-1)}\)</span> in the last iteration. This can be done as shown below:</p>
<p><span class="math display">\[z^{(t)} = g(W_zx^{(t)} + R_zy^{(t-1)} + b_z    -     (1) \]</span></p>
<p>where <span class="math inline">\(W_z\)</span> and <span class="math inline">\(R_z\)</span> are the weights associated with <span class="math inline">\(x^{(t)}\)</span> and <span class="math inline">\(y^{(t-1)}\)</span> respectively while <span class="math inline">\(b_z\)</span> stands for the bias weight vector.</p>
<p><strong>Input gate</strong>. During this step, we update the input gate that combines the current input <span class="math inline">\(x^{(t)}\)</span>, the output of that LSTM unit <span class="math inline">\(y^{(t-1)}\)</span> and the cell value <span class="math inline">\(c^{(t-1)}\)</span> in the last iteration. This can be done as shown below:</p>
<p><span class="math display">\[i_{(t)} =\sigma(W_ix^{(t)} + R_iy^{(t-1)} + p_i.c^{(t-1)} + b_i ) -(2) \]</span> where ‘<strong>.</strong>’ denotes point-wise multiplication of two vectors <span class="math inline">\(W_i,R_i\)</span> and <span class="math inline">\(p_i\)</span> are the weights associated with <span class="math inline">\(x^{(t)}\)</span>,<span class="math inline">\(y^{(t-1)}\)</span> and <span class="math inline">\(c^{(t-1)}\)</span> respectively while <span class="math inline">\(b_i\)</span> represents for the bias vector associated with this component.</p>
<p>In previous steps, the LSTM layer determines which information should be retained in the network’s cell states <span class="math inline">\(c^{(t)}\)</span>. This included the selection of the candidate values <span class="math inline">\(z^{(t)}\)</span> that could potentially be added to the cell states, and the activation values <span class="math inline">\(i^{(t)}\)</span> of the input gates.</p>
<p><strong>Forget gate</strong>. During this step, the LSTM unit determines which information should be removed from its previous cell states <span class="math inline">\(c^{(t-1)}\)</span>. Therefore, the activation values <span class="math inline">\(f^{(t)}\)</span> of the forget gates at the time step <em>t</em> are calculated based on the current input <span class="math inline">\(x^{(t)}\)</span>, the outputs <span class="math inline">\(y^{(t-1)}\)</span> and the state <span class="math inline">\(c^{(t-1)}\)</span> of the memory cells at the previous time step (t-1), the peephole connections, and the bias terms <span class="math inline">\(b_f\)</span> of the forget gates. This can be done as shown below:</p>
<p><span class="math display">\[  f_{(t)} = \sigma(W_fx^{(t)} + R_fy^{(t-1)} + p_f.c^{(t-1)} + b_f ) -(3)     \]</span> where <span class="math inline">\(W_f,R_f\)</span> and <span class="math inline">\(p_f\)</span> are the weights associated with <span class="math inline">\(x^{(t)}\)</span>,<span class="math inline">\(y^{(t-1)}\)</span> and <span class="math inline">\(c^{(t-1)}\)</span> respectively while <span class="math inline">\(b_f\)</span> denotes the bias weight vector.</p>
<p><strong>Cell</strong>. This step computes the cell values, which combines the block input <span class="math inline">\(z^{(t)}\)</span>, the input gate <span class="math inline">\(i^{(t)}\)</span> and the forget gate <span class="math inline">\(f_{(t)}\)</span> with the previous cell value. This can be done as shown below:</p>
<p><span class="math display">\[  c^{(t)} = z^{(t)}. i^{(t)} + c^{(t-1)}.f^{(t)}-(4) \]</span></p>
<p><strong>Output gate</strong>. This step calculates the output gate, which combines the current input <span class="math inline">\(x^{(t)}\)</span>, the output of that LSTM unit <span class="math inline">\(y^{(t-1)}\)</span> and the cell value <span class="math inline">\(c^{(t-1)}\)</span> in the last iteration. This can be done as shown below:</p>
<p><span class="math display">\[  o^{(t)} = \sigma(W_ox^{(t)} + R_oy^{(t-1)} + p_o.c^{(t-1)} + b_o ) -(5) \]</span> where <span class="math inline">\(W_o, R_o\)</span> and <span class="math inline">\(p_o\)</span> are the weights associated with <span class="math inline">\(x^{(t)}\)</span>,<span class="math inline">\(y^{(t-1)}\)</span> and <span class="math inline">\(c^{(t-1)}\)</span> respectively, while <span class="math inline">\(b_o\)</span> denoted for the bias weight vector.</p>
<p><strong>Block output</strong>. Finally, we calculate the block output, which combines the current cell value <span class="math inline">\(c^{(t)}\)</span> with the current output gate value as follows:</p>
<p><span class="math display">\[ y^{(t)} = g(c^{(t)}). o^{(t)}-(6) \]</span> In the above steps, <span class="math inline">\(\sigma\)</span>, g and h denote point-wise non-linear activation functions. The logistic sigmoid <span class="math inline">\(\sigma(x) = 1/(1+e^{1-x})\)</span> is used as a gate activation function, while the hyperbolic tangent <span class="math inline">\(g(x)= h(x)= tanh(x)\)</span> is often used as the block input and output activation function.<span class="citation" data-cites="van2020review">(<a href="#ref-van2020review" role="doc-biblioref">Van Houdt, Mosquera, and Nápoles 2020</a>)</span></p>
<p>A large part of real-world datasets are temporal in nature. Due to its distinctive properties, there are numerous unsolved problems with wide range of applications. Data collected over regular intervals of time is called time-series (TS) data and each data point is equally spaced over time. TS prediction is the method of forecasting upcoming trends/patterns of the given historical dataset with temporal features. A time series (TS) data can be break downed into trend, seasonality and error. A trend in TS can be observed when a certain pattern repeats on regular intervals of time due to external factors. In many real world scenarios, either of trend or seasonality are absent. After finding the nature of TS, various forecasting methods have to be applied on given TS. Given the TS, it is broadly classified into 2 categories i.e. stationary and non-stationary. A series is said to be stationary, if it does not depend on the time components like trend, seasonality effects. Mean and variances of such series are constant with respect to time. Stationary TS is easier to analyze and results skilful forecasting. A TS data is said to non-stationary if it has trend, seasonality effects in it and changes with respect to time. Statistical properties like mean, variance, sand standard deviation also changes with respect to time.<span class="citation" data-cites="chimmula2020time">(<a href="#ref-chimmula2020time" role="doc-biblioref">Chimmula and Zhang 2020</a>)</span></p>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
</section>
<section id="analysis-and-results" class="level2">
<h2 class="anchored" data-anchor-id="analysis-and-results">Analysis and Results</h2>
</section>
<section id="data-and-visualisation" class="level2">
<h2 class="anchored" data-anchor-id="data-and-visualisation">Data and Visualisation</h2>
</section>
<section id="statistical-modeling" class="level2">
<h2 class="anchored" data-anchor-id="statistical-modeling">Statistical Modeling</h2>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
</section>
<section id="references" class="level2 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-chimmula2020time" class="csl-entry" role="listitem">
Chimmula, Vinay Kumar Reddy, and Lei Zhang. 2020. <span>“Time Series Forecasting of COVID-19 Transmission in Canada Using LSTM Networks.”</span> <em>Chaos, Solitons &amp; Fractals</em> 135: 109864.
</div>
<div id="ref-gers2001lstm" class="csl-entry" role="listitem">
Gers, Felix A, and E Schmidhuber. 2001. <span>“LSTM Recurrent Networks Learn Simple Context-Free and Context-Sensitive Languages.”</span> <em>IEEE Transactions on Neural Networks</em> 12 (6): 1333–40.
</div>
<div id="ref-greff2016lstm" class="csl-entry" role="listitem">
Greff, Klaus, Rupesh K Srivastava, Jan Koutnı́k, Bas R Steunebrink, and Jürgen Schmidhuber. 2016. <span>“LSTM: A Search Space Odyssey.”</span> <em>IEEE Transactions on Neural Networks and Learning Systems</em> 28 (10): 2222–32.
</div>
<div id="ref-hochreiter1997long" class="csl-entry" role="listitem">
Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. <span>“Long Short-Term Memory.”</span> <em>Neural Computation</em> 9 (8): 1735–80.
</div>
<div id="ref-van2020review" class="csl-entry" role="listitem">
Van Houdt, Greg, Carlos Mosquera, and Gonzalo Nápoles. 2020. <span>“A Review on the Long Short-Term Memory Model.”</span> <em>Artificial Intelligence Review</em> 53: 5929–55.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>